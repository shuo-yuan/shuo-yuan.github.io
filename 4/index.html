<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 4: Neural Radience Fields</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        
        .part {
            background: white;
            margin: 20px 0;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .part h2 {
            color: #333;
            border-bottom: 2px solid #007bff;
            padding-bottom: 10px;
            margin-bottom: 20px;
        }
        
        
        .gif-container {
            text-align: center;
        }
        
        .gif-container img {
            max-width: 60%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
        }
        
        .gif-container p {
            margin-top: 15px;
            color: #666;
            font-size: 14px;
        }
        
        .selfie-row {
            display: flex;
            justify-content: space-between;
            align-items: center;
            gap: 15px;
            margin: 30px 0 20px 0;
            flex-wrap: nowrap;
            padding: 0 10px;
        }
        
        .code-row {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 20px;
            margin: 30px 0 20px 0;
        }
        
        .part2 .selfie-row {
            gap: 80px;
        }
        
        .selfie-item {
            display: flex;
            flex-direction: column;
            align-items: center;
            text-align: center;
            flex: 1;
            min-width: 0;
        }
        
        .selfie-row img {
            max-width: 200px;
            max-height: 200px;
            width: auto;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            object-fit: cover;
            margin-bottom: 8px;
        }
        
        .part2 .selfie-row img {
            max-width: 500px;
            max-height: 500px;
        }
        
        .selfie-caption {
            font-size: 12px;
            color: #666;
            font-weight: 500;
            margin-top: 4px;
        }
        
        .code-block {
            width: 100%;
            max-width: 1000px;
            margin: 0;
        }
        
        .code-block pre {
            background-color: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 15px;
            margin: 0;
            overflow: hidden;
            font-size: 11px;
            line-height: 1.4;
            height: auto;
        }
        
        .code-block code {
            text-align: left;
            display: block;
            white-space: pre-wrap;
            word-wrap: break-word;
            font-family: 'Courier New', monospace;
        }
        
        .code-caption {
            font-size: 12px;
            color: #666;
            font-weight: 500;
            margin-top: 8px;
            text-align: center;
        }
        
        .runtime-table {
            margin: 30px auto;
            border-collapse: collapse;
            width: 90%;
            max-width: 900px;
        }
        
        .runtime-table th, .runtime-table td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: center;
            width: 25%;
        }
        
        .runtime-table th {
            background-color: #f8f9fa;
            font-weight: bold;
        }
        
        .table-caption {
            font-size: 14px;
            color: #666;
            font-weight: 500;
            margin-top: 5px;
            margin-bottom: 10px;
            text-align: center;
        }
        
        /* Hybrid Images Layout Styles */
        .hybrid-container {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 40px;
            margin: 30px auto 50px auto;
            padding: 20px;
            border: 1px solid #e0e0e0;
            border-radius: 12px;
            background-color: #fafafa;
            max-width: 1000px;
        }
        
        .hybrid-left {
            display: flex;
            flex-direction: column;
            gap: 20px;
            flex: 1;
            max-width: 450px;
        }
        
        .hybrid-row {
            display: flex;
            gap: 20px;
            justify-content: center;
        }
        
        .hybrid-item {
            display: flex;
            flex-direction: column;
            align-items: center;
            text-align: center;
        }
        
        .hybrid-right {
            display: flex;
            flex-direction: column;
            align-items: center;
            text-align: center;
            flex: 0 0 auto;
            justify-content: center;
        }
        
        .hybrid-right img {
            border: 2px solid #333;
            border-radius: 12px;
            box-shadow: 0 4px 16px rgba(0,0,0,0.2);
        }
        
        /* Fix white space issues in hybrid containers */
        .hybrid-container img {
            display: block;
            object-fit: cover;
            object-position: center;
        }
        
        .hybrid-item {
            display: flex;
            flex-direction: column;
            align-items: center;
            text-align: center;
            height: 100%;
        }
        
        .hybrid-right {
            display: flex;
            flex-direction: column;
            align-items: center;
            text-align: center;
            flex: 0 0 auto;
            justify-content: center;
            height: 100%;
        }
        
        .part2 h3 {
            color: #444;
            font-size: 20px;
            margin-top: 40px;
            margin-bottom: 20px;
            text-align: center;
            font-weight: 600;
        }
        
        /* Specific styling for spectrum images */
        .hybrid-container .hybrid-left .hybrid-row {
            gap: 60px;
        }
        
        .hybrid-container .hybrid-left {
            gap: 60px;
        }
    </style>
</head>
<body>
    <h1 style="text-align: center; color: #333; margin-bottom: 40px;">Project 4: Neural Radience Fields</h1>

    <div class="part part1">
        <h2>Part 0: Calibrating Your Camera and Capturing a 3D Scan</h2>
        <p style="text-align: justify;">This part calibrates the cameta, captures the images for the object, and undistorts them for later reconstrcution.</p>
        <p style="text-align: justify;">The following images show the cloud of cameras visualized with Viser and the difference between the original images and the undistorted images.</p>

        <div class="selfie-row">
            <div class="selfie-item">
                <img src="pluto_camera_1.png" alt="Original Selfie" style="max-width: 500px; max-height: 500px;">
                <div class="selfie-caption">Image 1 for the captured Dataset</div>
            </div>
            <div class="selfie-item">
                <img src="pluto_camera_2.png" alt="Box Filter Result" style="max-width: 500px; max-height: 500px;">
                <div class="selfie-caption">Image 2 for the captured Dataset</div>
            </div>
        </div>

        <div class="selfie-row">
            <div class="selfie-item">
                <img src="pluto_undistort.png" alt="Original Selfie" style="max-width: 1000px; max-height: 1000px;">
                <div class="selfie-caption">comparison between the original and the undistorted images</div>
            </div>
        </div>

        </div>
    
    <div class="part part1">
        <h2>Part 1: Fit a Neural Field to a 2D Image</h2>
        <p style="text-align: justify;">To get started, we first fit a neural field to a 2D image. The coordinates are first transformed into positional embeddings, and then passed in a MLP. The MLP is constructed with 4 linear layers interleaved with ReLU functions, with a sigmoid function after the final layer. Adam is used as the optimizer with a learning rate of 0.01.</p>
        <p style="text-align: justify;">The frequency of the positional embeddings and the size of the linear layer are varied to see how these two factors affect the reconstrcution quality.</p>
        <p style="text-align: justify;">Images are also reconstructed at the checkpoints and are shown below. The PSNR curve from training is also shown below. The final reconstructed image is shown in the final checkpoint column.</p>       


        <div class="selfie-row">
            <div class="selfie-item">
                <img src="reconstructed_images.png" alt="homography matrix" style="max-width: 1000px; max-height: 5000px;">
                <div class="selfie-caption">2D Image Reconstrcution</div>
            </div>
        </div>

        <div class="selfie-row">
            <div class="selfie-item">
                <img src="psnr_curves.png" alt="homography matrix" style="max-width: 1000px; max-height: 1000px;">
                <div class="selfie-caption">Training PSNR Curve</div>
            </div>
        </div>       
    </div>
    
    <div class="part part1">
        <h2>Part 2: Fit a Neural Radiance Field from Multi-view Images</h2>
        <p style="text-align: justify;">We separately implement the following functions: transform, pixel_to_camera, pixel_to_ray for part 2.1. All functions are implemented in batched operation. The transform function implements a basic matrix vector multiplication, truncating the homogenous coordinates. The pixel_to_camera function converts pixel coordinates to camera coordinates (note that this correponds to a ray, which is why we need a scale argument to fix the point), and the pixel_to_ray function generates rays from the camera coordinates.</p>
        <p style="text-align: justify;">For part 2.2, we implement different sampling procedures. For the sample_ray_from_images function, we first sample pixels from the image and then use the pixel_to_ray function to generate the rays. We also sample points along the rays, where we uniformly select num_sample points between the arguments near and far, with optional random perturbation.</p>
        <p style="text-align: justify;">For part 2.3, we implement the RayDataset, and visualize the rays with Viser. Pictures of the rays sampled from the bulldozer images are shown below.</p>

        <div class="selfie-row">
            <div class="selfie-item">
                <img src="bulldozer_ray_single.png" alt="channing_court" style="max-width: 500px; max-height: 500px;">
                <div class="selfie-caption">Ray Visualization from a Single Image</div>
            </div>
            <div class="selfie-item">
                <img src="bulldozer_ray_visualization.png" alt="channing_court_nearest_neighbor" style="max-width: 500px; max-height: 500px;">
                <div class="selfie-caption">100 Rays sampled from all the Images</div>
            </div>
        </div>

        <p style="text-align: justify;">Finally, we implement the NeRF model with the following architecture in part 2.4.</p>

        <div class="selfie-row">
            <div class="selfie-item">
                <img src="nerf_structure.png" alt="roomates" style="max-width: 1000px; max-height: 2000px;">
                <div class="selfie-caption">Model Architecture</div>
            </div>
        </div>

        <p style="text-align: justify;">In part 2.5, we implement the volume rendering function, taking in a list of predicted RGB values and densities and outputting the predicted reconstructed pixel. Using the cumprod function in PyTorch for calculating the T_i values speed up the computation.</p>
        <p style="text-align: justify;">The following images visualize the training process, the validation PSNR curve, and the final reconstructed 3D bulldozer.</p>


        <div class="selfie-row">
            <div class="selfie-item">
                <img src="training_progression.png" alt="roomates" style="max-width: 1000px; max-height: 2000px;">
                <div class="selfie-caption">Training Progression</div>
            </div>
        </div>
        <div class="selfie-row">
            <div class="selfie-item">
                <img src="nerf_psnr_curve.png" alt="roomates" style="max-width: 1000px; max-height: 2000px;">
                <div class="selfie-caption">PSNR values evaluated on the validation set</div>
            </div>
        </div>
        <div class="selfie-row">
            <div class="selfie-item">
                <img src="bulldozer_novel_views.gif" alt="warped_lec_3" style="width: 1000px; height: 800px; object-fit: cover;">
                <div class="selfie-caption">Reconstrcution of the Bulldozer</div>
            </div>
        </div>
    </div>
    
    <div class="part part2">
        <h2>Part 2.6: Training with My Own Data</h2>
        <p style="text-align: justify;">This part of the project trains a NeRF model on my own data captured with my iPhone 13. The model architecture stays the same as the previous part. The only hyperparameters changed are the near and far values used when sampling the points along the ray.</p>
        <p style="text-align: justify;">Note that the quality of the reconstruction is low due to the fact that the tags are hidden behind the object in some directions, and therefore we lack the data from those directions.</p>

        <div class="selfie-row">
            <div class="selfie-item">
                <img src="pluto.png" alt="Original Selfie" style="max-width: 1000px; max-height: 1000px;">
                <div class="selfie-caption">Training Progression for my NeRF Data</div>
            </div>
        </div>

        <div class="selfie-row">
            <div class="selfie-item">
                <img src="training_loss.png" alt="warped_lec_1" style="width: 750px; height: 300px; object-fit: cover;">
                <div class="selfie-caption">Training Loss</div>
            </div>
            <div class="selfie-item">
                <img src="training_loss_psnr.png" alt="mask_lec_1" style="width: 750px; height: 300px; object-fit: cover;">
                <div class="selfie-caption">Training PSNR</div>
            </div>
        </div>

        <div class="selfie-row">
            <div class="selfie-item">
                <img src="lafufu.gif" alt="warped_lec_3" style="width: 1000px; height: 800px; object-fit: cover;">
                <div class="selfie-caption">Reconstrcution of my own Data</div>
            </div>
        </div>

        <p style="text-align: justify;">Note that due to the low quality of the reconstruction, I will include a reconstructed Lafufu with the staff captured dataset, proving the point that my implementation is flawless.</p>
        
        <div class="selfie-row">
            <div class="selfie-item">
                <img src="lafufu_staff.gif" alt="warped_lec_3" style="width: 1000px; height: 1000px; object-fit: cover;">
                <div class="selfie-caption">Reconstrcution of the Staff Data</div>
            </div>
        </div>

    </div>

</body>
</html>

